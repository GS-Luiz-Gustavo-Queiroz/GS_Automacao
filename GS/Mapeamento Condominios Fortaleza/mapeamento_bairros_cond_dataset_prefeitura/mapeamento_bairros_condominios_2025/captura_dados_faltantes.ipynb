{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4262f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f26f7",
   "metadata": {},
   "source": [
    "Nesse script, iremos capturar dados faltantes do nosso dataset, como nome fantasia, razão social, ddd1 e telefone1, ddd2 telefone2, dddfax fax, e-mail.\n",
    "\n",
    "- Chame a função **<i>captura_dados_faltantes_api(nome_do_arquivo)</i>** na qual o nome do arquivo deve ser do tipo \"condominios.csv\"\n",
    "- A função irá exportar um arquivo csv com o mesmo nome do arquivo concatenado com \"incrementado_\"\n",
    "- Ex.: chamando a função -> **<i>captura_dados_faltantes_api(\"condominios_total_parte1.csv\")</i>** o arquivo exportado será -> **<i>incrementado_condominios_total_parte1.csv</i>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa54d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def captura_dados_faltantes_api(nome_do_arquivo):\n",
    "    dataset = pd.read_csv((nome_do_arquivo), dtype=str, encoding='latin1') #carregando csv do dataset\n",
    "    dataset.insert(2, 'razao_social', np.nan) #adicao de coluna razao_social\n",
    "\n",
    "    cnpjs_para_consulta = dataset[\"cnpj\"].str.replace('/', '').str.replace('-', '') #removendo / e - dos cnpj para consultar\n",
    "\n",
    "    for i in range(0, dataset.shape[0]):\n",
    "        cnpj = cnpjs_para_consulta[i] #cnpj do registro atual do loop\n",
    "        dados_cnpj = requests.get(f\"https://publica.cnpj.ws/cnpj/{cnpj}\") #consulta na api\n",
    "        empresa = dados_cnpj.json() #dados json da empresa relacionada ao cnpj\n",
    "\n",
    "        razao_social = empresa[\"razao_social\"]\n",
    "        nome_fantasia = empresa[\"estabelecimento\"][\"nome_fantasia\"]\n",
    "        ddd1 = empresa[\"estabelecimento\"][\"ddd1\"]\n",
    "        telefone1 = empresa[\"estabelecimento\"][\"telefone1\"]\n",
    "        ddd2 = empresa[\"estabelecimento\"][\"ddd2\"]\n",
    "        telefone2 = empresa[\"estabelecimento\"][\"telefone2\"]\n",
    "        ddd_fax = empresa[\"estabelecimento\"][\"ddd_fax\"]\n",
    "        fax = empresa[\"estabelecimento\"][\"fax\"]\n",
    "        email = empresa[\"estabelecimento\"][\"email\"]\n",
    "\n",
    "        #a logica desses try catch é: se no dataset o dado é \"vazio\" NaN,\n",
    "        # então verificamos se o dado vindo da consulta não é vazio, e então atribuimos o dado\n",
    "        try:\n",
    "            np.isnan(dataset[\"razao_social\"][i])\n",
    "            if(razao_social == None):\n",
    "                pass\n",
    "            else:\n",
    "                dataset[\"razao_social\"][i] = razao_social\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            np.isnan(dataset[\"nome_fantasia\"][i])\n",
    "            if(nome_fantasia == None):\n",
    "                pass\n",
    "            else:\n",
    "                dataset[\"nome_fantasia\"][i] = nome_fantasia\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            np.isnan(dataset[\"ddd1\"][i])\n",
    "            if(ddd1 == None):\n",
    "                pass\n",
    "            else:\n",
    "                dataset[\"ddd1\"][i] = ddd1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            np.isnan(dataset[\"telefone1\"][i])\n",
    "            if(telefone1 == None):\n",
    "                pass\n",
    "            else:\n",
    "                dataset[\"telefone1\"][i] = telefone1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            np.isnan(dataset[\"ddd2\"][i])\n",
    "            if(ddd2 == None):\n",
    "                pass\n",
    "            else:\n",
    "                dataset[\"ddd2\"][i] = ddd2\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            np.isnan(dataset[\"telefone2\"][i])\n",
    "            if(telefone2 == None):\n",
    "                pass\n",
    "            else:\n",
    "                dataset[\"telefone2\"][i] = telefone2   \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            np.isnan(dataset[\"ddd_fax\"][i])\n",
    "            if(ddd_fax == None):\n",
    "                pass\n",
    "            else:\n",
    "                dataset[\"ddd_fax\"][i] = ddd_fax\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            np.isnan(dataset[\"fax\"][i])\n",
    "            if(fax == None):\n",
    "                pass\n",
    "            else:\n",
    "                dataset[\"fax\"][i] = fax\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            np.isnan(dataset[\"email\"][i])\n",
    "            if(email == None):\n",
    "                pass\n",
    "            else:\n",
    "                dataset[\"email\"][i] = email\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        os.system('cls' if os.name == 'nt' else 'clear') #limpar terminal\n",
    "        print(f\"{i+1} de {len(dataset)}\")\n",
    "\n",
    "        time.sleep(21)\n",
    "    \n",
    "\n",
    "    dataset.to_csv(\"incrementado_\"+nome_do_arquivo, index=False, encoding='latin1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef62918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"condominios_total.csv\", dtype=str, encoding='latin1')\n",
    "dataset_test = dataset[:5]\n",
    "dataset_test.to_csv(\"dataset_test.csv\", index=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b7107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_17292\\1405418780.py:29: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataset[\"razao_social\"][i] = razao_social\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_17292\\1405418780.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"razao_social\"][i] = razao_social\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_17292\\1405418780.py:29: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'EDIFICIO VILLA SERENA' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  dataset[\"razao_social\"][i] = razao_social\n"
     ]
    }
   ],
   "source": [
    "captura_dados_faltantes_api(\"dataset_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227ef46",
   "metadata": {},
   "source": [
    "### Testes de código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66d39cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"condominios_total.csv\", dtype=str, encoding='latin1')\n",
    "dataset\n",
    "\n",
    "#repartindo o dataset em 2 partes\n",
    "condominio_total_parte1 = dataset[:int(len(dataset)/2)]\n",
    "condominio_total_parte2 = dataset[int(len(dataset)/2) : len(dataset)]\n",
    "\n",
    "condominio_total_parte1.to_csv(\"condominios_total_parte1.csv\", index=False, encoding='latin1')\n",
    "condominio_total_parte1.to_csv(\"condominios_total_parte2.csv\", index=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97fe65ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnpjs_para_consulta = dataset[\"cnpj\"].str.replace('/', '').str.replace('-', '') #removendo / e - dos cnpj para consultar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f15ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_5740\\2385825668.py:22: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  dataset20[\"razao_social\"][i] = razao_social\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_5740\\2385825668.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset20[\"razao_social\"][i] = razao_social\n",
      "C:\\Users\\eduar\\AppData\\Local\\Temp\\ipykernel_5740\\2385825668.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'EDIFICIO VILLA SERENA' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  dataset20[\"razao_social\"][i] = razao_social\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, dataset20.shape[0]):\n",
    "    cnpj = cnpjs_para_consulta[i]\n",
    "    dados_cnpj = requests.get(f\"https://publica.cnpj.ws/cnpj/{cnpj}\")\n",
    "    empresa = dados_cnpj.json()\n",
    "    empresa\n",
    "\n",
    "    razao_social = empresa[\"razao_social\"]\n",
    "    nome_fantasia = empresa[\"estabelecimento\"][\"nome_fantasia\"]\n",
    "    ddd1 = empresa[\"estabelecimento\"][\"ddd1\"]\n",
    "    telefone1 = empresa[\"estabelecimento\"][\"telefone1\"]\n",
    "    ddd2 = empresa[\"estabelecimento\"][\"ddd2\"]\n",
    "    telefone2 = empresa[\"estabelecimento\"][\"telefone2\"]\n",
    "    ddd_fax = empresa[\"estabelecimento\"][\"ddd_fax\"]\n",
    "    fax = empresa[\"estabelecimento\"][\"fax\"]\n",
    "    email = empresa[\"estabelecimento\"][\"email\"]\n",
    "\n",
    "    try:\n",
    "        np.isnan(dataset20[\"razao_social\"][i])\n",
    "        if(razao_social == None):\n",
    "            pass\n",
    "        else:\n",
    "            dataset20[\"razao_social\"][i] = razao_social\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        np.isnan(dataset20[\"nome_fantasia\"][i])\n",
    "        if(nome_fantasia == None):\n",
    "            pass\n",
    "        else:\n",
    "            dataset20[\"nome_fantasia\"][i] = nome_fantasia\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        np.isnan(dataset20[\"ddd1\"][i])\n",
    "        if(ddd1 == None):\n",
    "            pass\n",
    "        else:\n",
    "            dataset20[\"ddd1\"][i] = ddd1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        np.isnan(dataset20[\"telefone1\"][i])\n",
    "        if(telefone1 == None):\n",
    "            pass\n",
    "        else:\n",
    "            dataset20[\"telefone1\"][i] = telefone1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        np.isnan(dataset20[\"ddd2\"][i])\n",
    "        if(ddd2 == None):\n",
    "            pass\n",
    "        else:\n",
    "            dataset20[\"ddd2\"][i] = ddd2\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        np.isnan(dataset20[\"telefone2\"][i])\n",
    "        if(telefone2 == None):\n",
    "            pass\n",
    "        else:\n",
    "            dataset20[\"telefone2\"][i] = telefone2   \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        np.isnan(dataset20[\"ddd_fax\"][i])\n",
    "        if(ddd_fax == None):\n",
    "            pass\n",
    "        else:\n",
    "            dataset20[\"ddd_fax\"][i] = ddd_fax\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        np.isnan(dataset20[\"fax\"][i])\n",
    "        if(fax == None):\n",
    "            pass\n",
    "        else:\n",
    "            dataset20[\"fax\"][i] = fax\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        np.isnan(dataset20[\"email\"][i])\n",
    "        if(email == None):\n",
    "            pass\n",
    "        else:\n",
    "            dataset20[\"email\"][i] = email\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    time.sleep(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf9bd10",
   "metadata": {},
   "source": [
    "### Testes e exports para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc898bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset20 = dataset[:20]\n",
    "dataset20.to_csv('./comparativo/dataset_original_20_registros.csv', index=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "458d8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset20.to_csv('./comparativo/dataset_incrementado_20_registros.csv', index=False, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6649ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "condominio_total_parte1 = dat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
